{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "from path import Path\n",
    "import gc\n",
    "import optuna\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from scipy.special import erfinv\n",
    "\n",
    "import tensorflow as tf\n",
    "gpus = tf.config.experimental.list_physical_devices('GPU')\n",
    "\n",
    "for gpu in gpus:\n",
    "    tf.config.experimental.set_memory_growth(gpu, True)\n",
    "\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import backend as K\n",
    "from tensorflow.keras.layers import Dense, Input, BatchNormalization,Dropout\n",
    "from tensorflow.keras.models import Model, load_model\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau\n",
    "from tensorflow.keras.regularizers import l2\n",
    "from tensorflow.keras.metrics import AUC\n",
    "from tensorflow.keras.utils import get_custom_objects\n",
    "from tensorflow.keras.layers import Activation, LeakyReLU\n",
    "\n",
    "get_custom_objects().update({'leaky-relu':Activation(LeakyReLU(alpha  = 0.2))})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gpu_cleanup(objects):\n",
    "    if objects:\n",
    "        del(objects)\n",
    "    K.clear_session()\n",
    "    gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Config:\n",
    "    input_path = Path('../')\n",
    "    dae_batch_size = 128\n",
    "    dae_num_epoch = 50\n",
    "    dae_architecture = [1500, 1500,1500]\n",
    "    reuse_autoencoder = False\n",
    "    batch_size = 128\n",
    "    num_epocs = 150\n",
    "    units = [64, 32]\n",
    "    input_dropout = 0.06\n",
    "    dropout = 0.08\n",
    "    regL2 = 0.09\n",
    "    activation = 'relu'\n",
    "\n",
    "    cv_folds = 5\n",
    "    nas = True\n",
    "    random_state = 0\n",
    "\n",
    "config = Config()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_csv(config.input_path/'input/train.csv', index_col= 'id')\n",
    "test = pd.read_csv(config.input_path/'input/test.csv', index_col= 'id')\n",
    "submission = pd.read_csv(config.input_path/'input/sample_submission.csv', index_col= 'id')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "calc_features = [feat for feat in train.columns if \"_calc\" in feat]\n",
    "cat_features = [feat for feat in train.columns if \"_cat\" in feat]\n",
    "target = train[\"target\"]\n",
    "train = train.drop(\"target\", axis=\"columns\")\n",
    "train = train.drop(calc_features, axis=\"columns\")\n",
    "test = test.drop(calc_features, axis=\"columns\")\n",
    "train = pd.get_dummies(train, columns=cat_features)\n",
    "test = pd.get_dummies(test, columns=cat_features)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "applying gaussrank to columns: ['ps_ind_01', 'ps_ind_03', 'ps_ind_14', 'ps_ind_15', 'ps_reg_01', 'ps_reg_02', 'ps_reg_03', 'ps_car_11', 'ps_car_12', 'ps_car_13', 'ps_car_14', 'ps_car_15']\n"
     ]
    }
   ],
   "source": [
    "print(\"applying gaussrank to columns: \", end = '')\n",
    "to_normalize = list()\n",
    "\n",
    "for k, col in enumerate(train.columns):\n",
    "    if '_bin' not in col and '_cat' not in col and '_missing' not in col:\n",
    "        to_normalize.append(col)\n",
    "print(to_normalize)\n",
    "\n",
    "def to_gauss(x): return np.sqrt(2) * erfinv(x)\n",
    "def normalize(data, norm_cols):\n",
    "    n = data.shape[0]\n",
    "    for col in norm_cols:\n",
    "        sorted_idx = data[col].sort_values().index.tolist()\n",
    "        uniform = np.linspace(start = -0.99, stop = 0.99, num = n)\n",
    "        normal = to_gauss(uniform)\n",
    "        normalized_col = pd.Series(index = sorted_idx, data = normal)\n",
    "        data[col] = normalized_col\n",
    "    return data\n",
    "\n",
    "train = normalize(train, to_normalize)\n",
    "test = normalize(test, to_normalize)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = train.columns\n",
    "train_index = train.index\n",
    "test_index = test.index\n",
    "train = train.values.astype(np.float32)\n",
    "test = test.values.astype(np.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\fuksy\\AppData\\Local\\Temp\\ipykernel_3156\\2068861814.py:31: NumbaDeprecationWarning: \u001b[1mThe 'nopython' keyword argument was not supplied to the 'numba.jit' decorator. The implicit default value for this argument is currently False, but it will be changed to True in Numba 0.59.0. See https://numba.readthedocs.io/en/stable/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit for details.\u001b[0m\n",
      "  @jit\n"
     ]
    }
   ],
   "source": [
    "def plot_keras_history(history, measures):\n",
    "    rows = len(measures)//2 + len(measures) % 2\n",
    "    fig, panels = plt.subplots(rows, 2, figsize = (15,5))\n",
    "    plt.subplots_adjust(top = 0.99, bottom = 0.01, hspace = 0.4, wspace = 0.2)\n",
    "\n",
    "    try:\n",
    "        panels = [item for sublist in panels for item in sublist]\n",
    "\n",
    "    except:\n",
    "        pass\n",
    "\n",
    "    for k, measure in enumerate(measures):\n",
    "        panel = panels[k]\n",
    "        panel.set_title(measure + 'history')\n",
    "        panel.plot(history.epoch, history.history['measure'], label = 'train '+measure)\n",
    "\n",
    "        try:\n",
    "            panel.plot(history.epoch,\n",
    "                       history.history['val_'+measure],\n",
    "                       label = 'validation '+measure)\n",
    "        except:\n",
    "            pass\n",
    "\n",
    "        panel.set(xlabel = 'epochs', ylabel = measure)\n",
    "        panel.legend()\n",
    "\n",
    "    plt.show(fig)\n",
    "\n",
    "\n",
    "from numba import jit\n",
    "@jit\n",
    "def eval_gini(y_true, y_pred):\n",
    "    y_true = np.asarray(y_true)\n",
    "    y_true = y_true[np.argsort(y_pred)]\n",
    "    ntrue = 0\n",
    "    gini = 0\n",
    "    delta = 0\n",
    "    n = len(y_true)\n",
    "    for i in range(n-1, -1, -1):\n",
    "        y_i = y_true[i]\n",
    "        ntrue += y_i\n",
    "        gini += y_i * delta\n",
    "        delta += 1 - y_i\n",
    "    gini = 1 - 2 * gini / (ntrue * (n - ntrue))\n",
    "    return gini\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def batch_generator(x, batch_size, shuffle = True, random_state = None):\n",
    "    \n",
    "    batch_index = 0 #initial batch starts at reference 0\n",
    "    n = x.shape[0] #total length of the data that is going generate the batchs\n",
    "\n",
    "    while True: #keep going\n",
    "        if batch_index == 0: #first run\n",
    "            index_array = np.arange(n) #setting the ordered index of the data \n",
    "            \n",
    "            if shuffle: #in case of shuffle, set the seed and shuffle the index\n",
    "                np.random.seed(seed = random_state)\n",
    "                index_array = np.random.permutation(n) #permutation has something similar to np.arange when used in integers\n",
    "\n",
    "            current_index = (batch_index * batch_size) % n #the current index is going to drop only when surprass n\n",
    "            if n>= current_index + batch_size: # if its not, then keep updating the batch_index\n",
    "                current_batch_size = batch_size\n",
    "                batch_index += 1\n",
    "\n",
    "            else: #when the actual batch surpass the number of data\n",
    "                current_batch_size = n - current_index #how many points are overpassing n\n",
    "                batch_index = 0 #return to the first batch\n",
    "            \n",
    "            batch = x[index_array[current_index:current_index+current_batch_size]] #\n",
    "\n",
    "            yield batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mixup_generator(X, batch_size, swaprate=0.15, shuffle=True, random_state=None):\n",
    "    if random_state is None:\n",
    "        random_state = np.randint(0, 999)\n",
    "    num_features = X.shape[1]\n",
    "    num_swaps = int(num_features * swaprate)    \n",
    "    generator_a = batch_generator(X, batch_size, shuffle, \n",
    "                                  random_state)\n",
    "    generator_b = batch_generator(X, batch_size, shuffle, \n",
    "                                  random_state + 1)\n",
    "    while True:\n",
    "        batch = next(generator_a)\n",
    "        mixed_batch = batch.copy()\n",
    "        effective_batch_size = batch.shape[0]\n",
    "        alternative_batch = next(generator_b)\n",
    "        assert((batch != alternative_batch).any())\n",
    "        for i in range(effective_batch_size):\n",
    "            swap_idx = np.random.choice(num_features, num_swaps, \n",
    "                                        replace=False)\n",
    "            mixed_batch[i, swap_idx] = alternative_batch[i, swap_idx]\n",
    "        yield (mixed_batch, batch)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_DAE(X, architecture = [1500,1500,1500]):\n",
    "    features = X.shape[1]\n",
    "    inputs = Input((features,))\n",
    "\n",
    "    for i, nodes in enumerate(architecture):\n",
    "        layer = Dense(nodes,\n",
    "                       activation = 'relu',\n",
    "                       use_bias = False,\n",
    "                       name = f'code_{i+1}')\n",
    "        \n",
    "        if i == 0:\n",
    "            x = layer(inputs)\n",
    "        else:\n",
    "            x = layer(x)\n",
    "\n",
    "        x = BatchNormalization()(x)\n",
    "    outputs = Dense(features,activation = 'linear')(x)\n",
    "    model = Model(inputs = inputs, outputs = outputs)\n",
    "    model.compile(optimizer = 'adam', loss = 'mse', metrics = ['mse','mae'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_dae_features(autoencoder, X, layers = [3], batch_size = 128):\n",
    "    data = []\n",
    "    for layer in layers:\n",
    "        if layer == 0:\n",
    "            data.append(X)\n",
    "        else:\n",
    "            get_layer_output = Model([autoencoder.layers[0].input],\n",
    "                                     [autoencoder.layers[layer].output])\n",
    "            \n",
    "            layer_output = get_layer_output.predict(X, batch_size = batch_size)\n",
    "\n",
    "            data.append(layer_output)\n",
    "        data = np.hstack(data)\n",
    "        return data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "def autoencoder_fit(X_train, X_valid, filename = 'dae',random_state = None, suppress_output = False):\n",
    "    if suppress_output:\n",
    "        verbose = 0\n",
    "    else:\n",
    "        verbose = 2\n",
    "        print('fitting a denoise autoencoder')\n",
    "        \n",
    "    tf.random.set_seed(seed = random_state)\n",
    "\n",
    "    generator = mixup_generator(X_train,\n",
    "                                batch_size=config.batch_size,\n",
    "                                swaprate=0.15,\n",
    "                                random_state=config.random_state)\n",
    "    \n",
    "    dae = get_DAE(X_train, architecture=config.dae_architecture)\n",
    "\n",
    "    steps_per_epoch = np.ceil(X_train.shape[0]/config.dae_batch_size)\n",
    "\n",
    "    early_stopping = EarlyStopping(monitor = 'val_mse',\n",
    "                                   mode = 'min',\n",
    "                                   patience = 5,\n",
    "                                   restore_best_weigths = True,\n",
    "                                   verbose = 0)\n",
    "    \n",
    "    history = dae.fit(generator,\n",
    "                      steps_per_epoch = steps_per_epoch,\n",
    "                      epochs = config.num_epocs, \n",
    "                      validation_data = (X_valid, X_valid),\n",
    "                      verbose = verbose)\n",
    "\n",
    "    if not suppress_output:\n",
    "        plot_keras_history(history, measures = ['mse','mae'])\n",
    "\n",
    "    dae.save(filename)\n",
    "    return dae\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dense_blocks(x, units, activation, regL2, dropout):\n",
    "    kernel_initializer = keras.initializers.RandomNormal(mean = 0.0,\n",
    "                                                         stddev = 0.01, seed = config.random_state)\n",
    "    \n",
    "    for k,layer_units in enumerate(units):\n",
    "        if regL2 >0:\n",
    "            x = Dense(layer_units, activation=activation,\n",
    "                      kernel_initializer = kernel_initializer,\n",
    "                      kernel_regularizer = l2(regL2))(x)\n",
    "            \n",
    "        else:\n",
    "            x = Dense(layers_units, activation = activation,\n",
    "                      kernel_initializer = kernel_initializer)(x)\n",
    "            \n",
    "        if dropout > 0:\n",
    "            x = Dropout(dropout)(x)\n",
    "\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dnn_model(dae, units = [4500,1000,1000],\n",
    "              input_dropout = 0.1, dropout = 0.5,\n",
    "              regL2 = 0.05,\n",
    "              activation = 'relu'):\n",
    "    \n",
    "    inputs = dae.get_layer('code_2').output\n",
    "    \n",
    "    if input_dropout > 0 :\n",
    "        x = Dropout(input_dropout)(inputs)\n",
    "\n",
    "    else:\n",
    "        x = tf.keras.layers.Layer()(inputs)\n",
    "        \n",
    "    x = dense_blocks(x, units, activation, regL2, dropout)\n",
    "    outputs = Dense(1, activation = 'sigmoid')(x)\n",
    "\n",
    "    model = Model(inputs = dae.input, outputs = outputs)    \n",
    "    model.compile(optimizer = keras.optimizers.Adam(learning_rate=0.001),\n",
    "                  loss = keras.losses.binary_crossentropy,\n",
    "                  metrics = [AUC(name = 'auc')])\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_fitting(X_train, y_train, X_valid, y_valid,\n",
    "                  autoencoder,\n",
    "                  filename,\n",
    "                  random_state = None,\n",
    "                  suppress_output = False):\n",
    "    \n",
    "    if suppress_output:\n",
    "        verbose = 0\n",
    "\n",
    "    else:\n",
    "        print('fitting model')\n",
    "        verbose = 2\n",
    "    \n",
    "    early_stopping = EarlyStopping(monitor='val_auc',\n",
    "                                   mode = 'max',\n",
    "                                   patience = 10,\n",
    "                                   restore_best_weights = True,\n",
    "                                   verbose = 0)\n",
    "    \n",
    "    rlrop = ReduceLROnPlateau(monitor = 'val_auc',\n",
    "                              mode = 'max',\n",
    "                              patience = 2,\n",
    "                              factor = 0.75,\n",
    "                              verbose = 0)\n",
    "    \n",
    "    tf.random.set_seed(seed = random_state)\n",
    "    model = dnn_model(autoencoder,\n",
    "                      units = config.units,\n",
    "                      input_dropout=config.input_dropout,\n",
    "                      dropout=config.dropout,\n",
    "                      regL2 = config.regL2,\n",
    "                      activation=config.activation)\n",
    "    \n",
    "    history = model.fit(X_train,y_train,\n",
    "                        epochs = config.num_epocs,\n",
    "                        batch_size = config.batch_size,\n",
    "                        validation_data = (X_valid, y_valid),\n",
    "                        callbacks = [early_stopping, rlrop],\n",
    "                        shuffle = True,\n",
    "                        verbose = verbose)\n",
    "    model.save(filename)\n",
    "\n",
    "    if not suppress_output:\n",
    "        plot_keras_history(history, measures = ['loss','auc'])\n",
    "\n",
    "    return model,history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "if config.nas is True:\n",
    "    def evaluate():\n",
    "        metric_evaluations = list()\n",
    "        skf = StratifiedKFold(n_splits = config.cv_folds,\n",
    "                              shuffle=True,\n",
    "                              random_state=config.random_state)\n",
    "        \n",
    "        for k, (train_idx, valid_idx) in enumerate(skf.split(train,target)):\n",
    "            X_train, y_train = train[train_idx,:], target[train_idx]\n",
    "            X_valid, y_valid = train[valid_idx,:], target[valid_idx]\n",
    "\n",
    "            if config.reuse_autoencoder:\n",
    "                autoencoder = load_model(f\"./dae_fold{k}\")\n",
    "            else:\n",
    "                autoencoder = autoencoder_fit(X_train,X_valid,\n",
    "                                              filename= f'./dae_fold{k}',\n",
    "                                              random_state=config.random_state,\n",
    "                                              suppress_output=True)\n",
    "                \n",
    "            model,_ = model_fitting(X_train,y_train, X_valid,y_valid,\n",
    "                                    autoencoder=autoencoder,\n",
    "                                    filename = f'dnn_model_fold{k}',\n",
    "                                    random_state = config.random_state,\n",
    "                                    suppress_output = True)\n",
    "            \n",
    "            val_preds = model.predict(X_valid, batch_size = 128, verbose = 0)\n",
    "            best_score = eval_gini(y_true = y_valid, y_pred = np.ravel(val_preds))\n",
    "            metric_evaluations.append(best_score)\n",
    "            gpu_cleanup([autoencoder, model])\n",
    "\n",
    "        return np.mean(metric_evaluations)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-07-20 08:53:17,764] A new study created in memory with name: no-name-91761593-6d1d-47b6-8102-f3eeb02413e7\n",
      "[W 2023-07-20 08:53:18,123] Trial 0 failed with parameters: {'first_layer': 128, 'second_layer': 0, 'third_layer': 32, 'input_droput': 0.41397418263980235, 'dropout': 0.32289256322728677, 'regL2': 0.077476909525998, 'activation': 'selu'} because of the following error: ValueError('too many values to unpack (expected 2)').\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\fuksy\\anaconda3\\Lib\\site-packages\\optuna\\study\\_optimize.py\", line 200, in _run_trial\n",
      "    value_or_values = func(trial)\n",
      "                      ^^^^^^^^^^^\n",
      "  File \"C:\\Users\\fuksy\\AppData\\Local\\Temp\\ipykernel_3156\\1475215444.py\", line 19, in objective\n",
      "    return evaluate()\n",
      "           ^^^^^^^^^^\n",
      "  File \"C:\\Users\\fuksy\\AppData\\Local\\Temp\\ipykernel_3156\\1472530446.py\", line 9, in evaluate\n",
      "    X_train, y_train = train[train_idx,:]; target[train_idx]\n",
      "    ^^^^^^^^^^^^^^^^\n",
      "ValueError: too many values to unpack (expected 2)\n",
      "[W 2023-07-20 08:53:18,125] Trial 0 failed with value None.\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "too many values to unpack (expected 2)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[46], line 22\u001b[0m\n\u001b[0;32m     19\u001b[0m     \u001b[39mreturn\u001b[39;00m evaluate()\n\u001b[0;32m     21\u001b[0m study \u001b[39m=\u001b[39m optuna\u001b[39m.\u001b[39mcreate_study(direction \u001b[39m=\u001b[39m \u001b[39m'\u001b[39m\u001b[39mmaximize\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[1;32m---> 22\u001b[0m study\u001b[39m.\u001b[39moptimize(objective, n_trials\u001b[39m=\u001b[39m\u001b[39m60\u001b[39m)\n\u001b[0;32m     23\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39m'\u001b[39m\u001b[39mbest gini score\u001b[39m\u001b[39m'\u001b[39m, study\u001b[39m.\u001b[39mbest_value)\n\u001b[0;32m     24\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39m'\u001b[39m\u001b[39mbest params\u001b[39m\u001b[39m'\u001b[39m, study\u001b[39m.\u001b[39mbest_params)\n",
      "File \u001b[1;32mc:\\Users\\fuksy\\anaconda3\\Lib\\site-packages\\optuna\\study\\study.py:443\u001b[0m, in \u001b[0;36mStudy.optimize\u001b[1;34m(self, func, n_trials, timeout, n_jobs, catch, callbacks, gc_after_trial, show_progress_bar)\u001b[0m\n\u001b[0;32m    339\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39moptimize\u001b[39m(\n\u001b[0;32m    340\u001b[0m     \u001b[39mself\u001b[39m,\n\u001b[0;32m    341\u001b[0m     func: ObjectiveFuncType,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    348\u001b[0m     show_progress_bar: \u001b[39mbool\u001b[39m \u001b[39m=\u001b[39m \u001b[39mFalse\u001b[39;00m,\n\u001b[0;32m    349\u001b[0m ) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m    350\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\"Optimize an objective function.\u001b[39;00m\n\u001b[0;32m    351\u001b[0m \n\u001b[0;32m    352\u001b[0m \u001b[39m    Optimization is done by choosing a suitable set of hyperparameter values from a given\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    440\u001b[0m \u001b[39m            If nested invocation of this method occurs.\u001b[39;00m\n\u001b[0;32m    441\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 443\u001b[0m     _optimize(\n\u001b[0;32m    444\u001b[0m         study\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m,\n\u001b[0;32m    445\u001b[0m         func\u001b[39m=\u001b[39mfunc,\n\u001b[0;32m    446\u001b[0m         n_trials\u001b[39m=\u001b[39mn_trials,\n\u001b[0;32m    447\u001b[0m         timeout\u001b[39m=\u001b[39mtimeout,\n\u001b[0;32m    448\u001b[0m         n_jobs\u001b[39m=\u001b[39mn_jobs,\n\u001b[0;32m    449\u001b[0m         catch\u001b[39m=\u001b[39m\u001b[39mtuple\u001b[39m(catch) \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(catch, Iterable) \u001b[39melse\u001b[39;00m (catch,),\n\u001b[0;32m    450\u001b[0m         callbacks\u001b[39m=\u001b[39mcallbacks,\n\u001b[0;32m    451\u001b[0m         gc_after_trial\u001b[39m=\u001b[39mgc_after_trial,\n\u001b[0;32m    452\u001b[0m         show_progress_bar\u001b[39m=\u001b[39mshow_progress_bar,\n\u001b[0;32m    453\u001b[0m     )\n",
      "File \u001b[1;32mc:\\Users\\fuksy\\anaconda3\\Lib\\site-packages\\optuna\\study\\_optimize.py:66\u001b[0m, in \u001b[0;36m_optimize\u001b[1;34m(study, func, n_trials, timeout, n_jobs, catch, callbacks, gc_after_trial, show_progress_bar)\u001b[0m\n\u001b[0;32m     64\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m     65\u001b[0m     \u001b[39mif\u001b[39;00m n_jobs \u001b[39m==\u001b[39m \u001b[39m1\u001b[39m:\n\u001b[1;32m---> 66\u001b[0m         _optimize_sequential(\n\u001b[0;32m     67\u001b[0m             study,\n\u001b[0;32m     68\u001b[0m             func,\n\u001b[0;32m     69\u001b[0m             n_trials,\n\u001b[0;32m     70\u001b[0m             timeout,\n\u001b[0;32m     71\u001b[0m             catch,\n\u001b[0;32m     72\u001b[0m             callbacks,\n\u001b[0;32m     73\u001b[0m             gc_after_trial,\n\u001b[0;32m     74\u001b[0m             reseed_sampler_rng\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m,\n\u001b[0;32m     75\u001b[0m             time_start\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m,\n\u001b[0;32m     76\u001b[0m             progress_bar\u001b[39m=\u001b[39mprogress_bar,\n\u001b[0;32m     77\u001b[0m         )\n\u001b[0;32m     78\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[0;32m     79\u001b[0m         \u001b[39mif\u001b[39;00m n_jobs \u001b[39m==\u001b[39m \u001b[39m-\u001b[39m\u001b[39m1\u001b[39m:\n",
      "File \u001b[1;32mc:\\Users\\fuksy\\anaconda3\\Lib\\site-packages\\optuna\\study\\_optimize.py:163\u001b[0m, in \u001b[0;36m_optimize_sequential\u001b[1;34m(study, func, n_trials, timeout, catch, callbacks, gc_after_trial, reseed_sampler_rng, time_start, progress_bar)\u001b[0m\n\u001b[0;32m    160\u001b[0m         \u001b[39mbreak\u001b[39;00m\n\u001b[0;32m    162\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m--> 163\u001b[0m     frozen_trial \u001b[39m=\u001b[39m _run_trial(study, func, catch)\n\u001b[0;32m    164\u001b[0m \u001b[39mfinally\u001b[39;00m:\n\u001b[0;32m    165\u001b[0m     \u001b[39m# The following line mitigates memory problems that can be occurred in some\u001b[39;00m\n\u001b[0;32m    166\u001b[0m     \u001b[39m# environments (e.g., services that use computing containers such as GitHub Actions).\u001b[39;00m\n\u001b[0;32m    167\u001b[0m     \u001b[39m# Please refer to the following PR for further details:\u001b[39;00m\n\u001b[0;32m    168\u001b[0m     \u001b[39m# https://github.com/optuna/optuna/pull/325.\u001b[39;00m\n\u001b[0;32m    169\u001b[0m     \u001b[39mif\u001b[39;00m gc_after_trial:\n",
      "File \u001b[1;32mc:\\Users\\fuksy\\anaconda3\\Lib\\site-packages\\optuna\\study\\_optimize.py:251\u001b[0m, in \u001b[0;36m_run_trial\u001b[1;34m(study, func, catch)\u001b[0m\n\u001b[0;32m    244\u001b[0m         \u001b[39massert\u001b[39;00m \u001b[39mFalse\u001b[39;00m, \u001b[39m\"\u001b[39m\u001b[39mShould not reach.\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    246\u001b[0m \u001b[39mif\u001b[39;00m (\n\u001b[0;32m    247\u001b[0m     frozen_trial\u001b[39m.\u001b[39mstate \u001b[39m==\u001b[39m TrialState\u001b[39m.\u001b[39mFAIL\n\u001b[0;32m    248\u001b[0m     \u001b[39mand\u001b[39;00m func_err \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m\n\u001b[0;32m    249\u001b[0m     \u001b[39mand\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39misinstance\u001b[39m(func_err, catch)\n\u001b[0;32m    250\u001b[0m ):\n\u001b[1;32m--> 251\u001b[0m     \u001b[39mraise\u001b[39;00m func_err\n\u001b[0;32m    252\u001b[0m \u001b[39mreturn\u001b[39;00m frozen_trial\n",
      "File \u001b[1;32mc:\\Users\\fuksy\\anaconda3\\Lib\\site-packages\\optuna\\study\\_optimize.py:200\u001b[0m, in \u001b[0;36m_run_trial\u001b[1;34m(study, func, catch)\u001b[0m\n\u001b[0;32m    198\u001b[0m \u001b[39mwith\u001b[39;00m get_heartbeat_thread(trial\u001b[39m.\u001b[39m_trial_id, study\u001b[39m.\u001b[39m_storage):\n\u001b[0;32m    199\u001b[0m     \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m--> 200\u001b[0m         value_or_values \u001b[39m=\u001b[39m func(trial)\n\u001b[0;32m    201\u001b[0m     \u001b[39mexcept\u001b[39;00m exceptions\u001b[39m.\u001b[39mTrialPruned \u001b[39mas\u001b[39;00m e:\n\u001b[0;32m    202\u001b[0m         \u001b[39m# TODO(mamu): Handle multi-objective cases.\u001b[39;00m\n\u001b[0;32m    203\u001b[0m         state \u001b[39m=\u001b[39m TrialState\u001b[39m.\u001b[39mPRUNED\n",
      "Cell \u001b[1;32mIn[46], line 19\u001b[0m, in \u001b[0;36mobjective\u001b[1;34m(trial)\u001b[0m\n\u001b[0;32m     16\u001b[0m config\u001b[39m.\u001b[39mregL2 \u001b[39m=\u001b[39m params[\u001b[39m'\u001b[39m\u001b[39mregL2\u001b[39m\u001b[39m'\u001b[39m]\n\u001b[0;32m     17\u001b[0m config\u001b[39m.\u001b[39mactivation \u001b[39m=\u001b[39m params[\u001b[39m'\u001b[39m\u001b[39mactivation\u001b[39m\u001b[39m'\u001b[39m]\n\u001b[1;32m---> 19\u001b[0m \u001b[39mreturn\u001b[39;00m evaluate()\n",
      "Cell \u001b[1;32mIn[45], line 9\u001b[0m, in \u001b[0;36mevaluate\u001b[1;34m()\u001b[0m\n\u001b[0;32m      4\u001b[0m skf \u001b[39m=\u001b[39m StratifiedKFold(n_splits \u001b[39m=\u001b[39m config\u001b[39m.\u001b[39mcv_folds,\n\u001b[0;32m      5\u001b[0m                       shuffle\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m,\n\u001b[0;32m      6\u001b[0m                       random_state\u001b[39m=\u001b[39mconfig\u001b[39m.\u001b[39mrandom_state)\n\u001b[0;32m      8\u001b[0m \u001b[39mfor\u001b[39;00m k, (train_idx, valid_idx) \u001b[39min\u001b[39;00m \u001b[39menumerate\u001b[39m(skf\u001b[39m.\u001b[39msplit(train,target)):\n\u001b[1;32m----> 9\u001b[0m     X_train, y_train \u001b[39m=\u001b[39m train[train_idx,:]; target[train_idx]\n\u001b[0;32m     10\u001b[0m     X_valid, y_valid \u001b[39m=\u001b[39m train[valid_idx,:]; target[valid_idx]\n\u001b[0;32m     12\u001b[0m     \u001b[39mif\u001b[39;00m config\u001b[39m.\u001b[39mreuse_autoencoder:\n",
      "\u001b[1;31mValueError\u001b[0m: too many values to unpack (expected 2)"
     ]
    }
   ],
   "source": [
    "def objective(trial):\n",
    "    params = {'first_layer':trial.suggest_categorical('first_layer',[8,16,32,64,128,256,512]),\n",
    "              'second_layer':trial.suggest_categorical('second_layer',[0,8,16,32,64,128,256]),\n",
    "              'third_layer':trial.suggest_categorical('third_layer',[0,8,16,32,64,128,256]),\n",
    "              'input_drop':trial.suggest_float('input_droput',0.0, 0.5),\n",
    "              'dropout':trial.suggest_float('dropout', 0.0, 0.5),\n",
    "              'regL2':trial.suggest_float('regL2',0.0, 0.1),\n",
    "              'activation':trial.suggest_categorical('activation',['relu','leaky-relu','selu'])}\n",
    "    \n",
    "    config.units = [nodes for nodes in [params['first_layer'],\n",
    "                                        params['second_layer'],\n",
    "                                        params['third_layer']] if nodes >0 ]\n",
    "    \n",
    "    config.input_dropout = params['input_drop']\n",
    "    config.dropout = params['dropout']\n",
    "    config.regL2 = params['regL2']\n",
    "    config.activation = params['activation']\n",
    "\n",
    "    return evaluate()\n",
    "\n",
    "study = optuna.create_study(direction = 'maximize')\n",
    "study.optimize(objective, n_trials=60)\n",
    "print('best gini score', study.best_value)\n",
    "print('best params', study.best_params)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "config.units = [nodes for nodes in [study.best_params['first_layer'],\n",
    "                                     study.best_params['second_layer'],\n",
    "                                       study.best_params['third_layer']] if nodes > 0]\n",
    "\n",
    "config.input_dropout = study.best_params['input_dropout']\n",
    "    config.dropout = study.best_params['dropout']\n",
    "    config.regL2 = study.best_params['regL2']\n",
    "    config.activation = study.best_params['activation']\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
