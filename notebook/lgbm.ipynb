{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import optuna\n",
    "import lightgbm as lgb\n",
    "from path import Path\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "class Config:\n",
    "    input_path = Path('../input')\n",
    "    optuna_lgb = False\n",
    "    n_estimators = 1500\n",
    "    early_stopping_round = 150\n",
    "    cv_folds = 5\n",
    "    random_state = 0\n",
    "    params = {'objective': 'binary',\n",
    "              'boosting_type': 'gbdt',\n",
    "              'learning_rate': 0.01,\n",
    "              'max_bin': 25,\n",
    "              'num_leaves': 31,\n",
    "              'min_child_samples': 1500,\n",
    "              'colsample_bytree': 0.7,\n",
    "              'subsample_freq': 1,\n",
    "              'subsample': 0.7,\n",
    "              'reg_alpha': 1.0,\n",
    "              'reg_lambda': 1.0,\n",
    "              'verbosity': 0,\n",
    "              'random_state': 0}\n",
    "    \n",
    "config = Config()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_csv(config.input_path/'train.csv',index_col='id')\n",
    "test = pd.read_csv(config.input_path/'test.csv', index_col= 'id')\n",
    "submission = pd.read_csv(config.input_path/'sample_submission.csv', index_col='id')\n",
    "\n",
    "calc_features = [feat for feat in train.columns if \"_calc\" in feat]\n",
    "cat_features = [feat for feat in train.columns if \"_cat\" in feat]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "target = train['target']\n",
    "train = train.drop(\"target\", axis  = 'columns')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#removing calc features since they do not accomplish good results anyway\n",
    "train = train.drop(calc_features, axis = 'columns')\n",
    "test = test.drop(calc_features, axis = 'columns')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\fuksy\\AppData\\Local\\Temp\\ipykernel_19568\\1989436427.py:2: NumbaDeprecationWarning: \u001b[1mThe 'nopython' keyword argument was not supplied to the 'numba.jit' decorator. The implicit default value for this argument is currently False, but it will be changed to True in Numba 0.59.0. See https://numba.readthedocs.io/en/stable/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit for details.\u001b[0m\n",
      "  @jit\n"
     ]
    }
   ],
   "source": [
    "from numba import jit\n",
    "@jit\n",
    "def eval_gini(y_true, y_pred):\n",
    "    y_true = np.asarray(y_true)\n",
    "    y_true = y_true[np.argsort(y_pred)]\n",
    "    ntrue = 0\n",
    "    gini = 0\n",
    "    delta = 0\n",
    "    n = len(y_true)\n",
    "    for i in range(n-1, -1, -1):\n",
    "        y_i = y_true[i]\n",
    "        ntrue += y_i\n",
    "        gini += y_i * delta\n",
    "        delta += 1 - y_i\n",
    "    gini = 1 - 2 * gini / (ntrue * (n - ntrue))\n",
    "    return gini\n",
    "def gini_lgb(y_true, y_pred):\n",
    "    eval_name = 'normalized_gini_coef'\n",
    "    eval_result = eval_gini(y_true, y_pred)\n",
    "    is_higher_better = True\n",
    "    return eval_name, eval_result, is_higher_better\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "if config.optuna_lgb:\n",
    "    def objective(trial):\n",
    "        params = {\n",
    "            'learning_rate':trial.suggest_float(\"learning_rate\",0.01,1.0),\n",
    "            'num_leaves':trial.suggest_int(\"num_leaves\", 3 ,255),\n",
    "            'min_child_samples':trial.suggest_int(\"min_child_samples\",3,30000),\n",
    "            'subsample_freq':trial.suggest_int(\"subsample_freq\",0,10),\n",
    "            'subsample':trial.suggest_float(\"subsample\", 0.1, 1,0),\n",
    "            'reg_lambda':trial.suggest_loguniform(\"reg_lambda\",1e-9,10.0)\n",
    "        }\n",
    "\n",
    "        score = list()\n",
    "        skf = StratifiedKFold(n_splits = config.cv_folds,\n",
    "                               shuffle=True,\n",
    "                               random_state = config.random_state)\n",
    "        \n",
    "        for train_idx, valid_idx in skf.split(train,target):\n",
    "            X_train = train.iloc[train_idx]\n",
    "            y_train = target.iloc[train_idx]\n",
    "            X_valid = train.iloc[valid_idx]\n",
    "            y_valid = target.iloc[valid_idx]\n",
    "\n",
    "            model = lgb.LGBMClassifier(**params,\n",
    "                                       n_estimators=1500,\n",
    "                                       early_stopping = 150,\n",
    "                                       force_row_wise = True)\n",
    "            callbacks = [lgb.early_stopping(stopping_rounds=150,\n",
    "                                            verbose = False)]\n",
    "            \n",
    "            model.fit(X_train,y_train,\n",
    "                      eval_set = [(X_valid,y_valid)],\n",
    "                      eval_metric=gini_lgb,\n",
    "                      callbacks=callbacks)\n",
    "            \n",
    "            score.append(model.best_score_['valid_0']['normalized_gini_coef'])\n",
    "\n",
    "        return np.mean(score)\n",
    "    study = optuna.create_study(direction = 'maximize')\n",
    "    print(\"best gini\", study.best_value)\n",
    "    print(\"best paras\", study.best_params)\n",
    "\n",
    "    params = {\n",
    "        'objective':'binary',\n",
    "        ' boosting_type':'gbdt',\n",
    "        'verbosity':0,\n",
    "        'random_state':0\n",
    "    }\n",
    "\n",
    "    params.update(study.best_params)\n",
    "\n",
    "else:\n",
    "    params = config.params\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CV fold 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\fuksy\\anaconda3\\Lib\\site-packages\\joblib\\externals\\loky\\backend\\context.py:110: UserWarning: Could not find the number of physical cores for the following reason:\n",
      "found 0 physical cores < 1\n",
      "Returning the number of logical cores instead. You can silence this warning by setting LOKY_MAX_CPU_COUNT to the number of cores you want to use.\n",
      "  warnings.warn(\n",
      "  File \"c:\\Users\\fuksy\\anaconda3\\Lib\\site-packages\\joblib\\externals\\loky\\backend\\context.py\", line 217, in _count_physical_cores\n",
      "    raise ValueError(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 150 rounds\n",
      "[100]\tvalid_0's binary_logloss: 0.153284\tvalid_0's normalized_gini_coef: 0.272472\n",
      "[200]\tvalid_0's binary_logloss: 0.152333\tvalid_0's normalized_gini_coef: 0.279339\n",
      "[300]\tvalid_0's binary_logloss: 0.151907\tvalid_0's normalized_gini_coef: 0.285607\n",
      "[400]\tvalid_0's binary_logloss: 0.151663\tvalid_0's normalized_gini_coef: 0.28995\n",
      "[500]\tvalid_0's binary_logloss: 0.151529\tvalid_0's normalized_gini_coef: 0.292425\n",
      "[600]\tvalid_0's binary_logloss: 0.15146\tvalid_0's normalized_gini_coef: 0.293545\n",
      "[700]\tvalid_0's binary_logloss: 0.151417\tvalid_0's normalized_gini_coef: 0.294406\n",
      "[800]\tvalid_0's binary_logloss: 0.151393\tvalid_0's normalized_gini_coef: 0.2949\n",
      "[900]\tvalid_0's binary_logloss: 0.151392\tvalid_0's normalized_gini_coef: 0.294881\n",
      "Early stopping, best iteration is:\n",
      "[802]\tvalid_0's binary_logloss: 0.151393\tvalid_0's normalized_gini_coef: 0.294906\n",
      "CV fold 1\n",
      "Training until validation scores don't improve for 150 rounds\n",
      "[100]\tvalid_0's binary_logloss: 0.153562\tvalid_0's normalized_gini_coef: 0.256141\n",
      "[200]\tvalid_0's binary_logloss: 0.152784\tvalid_0's normalized_gini_coef: 0.26106\n",
      "[300]\tvalid_0's binary_logloss: 0.152507\tvalid_0's normalized_gini_coef: 0.264436\n",
      "[400]\tvalid_0's binary_logloss: 0.15238\tvalid_0's normalized_gini_coef: 0.266843\n",
      "[500]\tvalid_0's binary_logloss: 0.152326\tvalid_0's normalized_gini_coef: 0.268244\n",
      "[600]\tvalid_0's binary_logloss: 0.1523\tvalid_0's normalized_gini_coef: 0.269268\n",
      "[700]\tvalid_0's binary_logloss: 0.152287\tvalid_0's normalized_gini_coef: 0.269867\n",
      "[800]\tvalid_0's binary_logloss: 0.152276\tvalid_0's normalized_gini_coef: 0.270375\n",
      "[900]\tvalid_0's binary_logloss: 0.152286\tvalid_0's normalized_gini_coef: 0.270253\n",
      "Early stopping, best iteration is:\n",
      "[795]\tvalid_0's binary_logloss: 0.152274\tvalid_0's normalized_gini_coef: 0.270445\n",
      "CV fold 2\n",
      "Training until validation scores don't improve for 150 rounds\n",
      "[100]\tvalid_0's binary_logloss: 0.153557\tvalid_0's normalized_gini_coef: 0.249482\n",
      "[200]\tvalid_0's binary_logloss: 0.152753\tvalid_0's normalized_gini_coef: 0.257365\n",
      "[300]\tvalid_0's binary_logloss: 0.152392\tvalid_0's normalized_gini_coef: 0.264671\n",
      "[400]\tvalid_0's binary_logloss: 0.152215\tvalid_0's normalized_gini_coef: 0.268562\n",
      "[500]\tvalid_0's binary_logloss: 0.152119\tvalid_0's normalized_gini_coef: 0.271032\n",
      "[600]\tvalid_0's binary_logloss: 0.152064\tvalid_0's normalized_gini_coef: 0.27238\n",
      "[700]\tvalid_0's binary_logloss: 0.152029\tvalid_0's normalized_gini_coef: 0.273347\n",
      "[800]\tvalid_0's binary_logloss: 0.152014\tvalid_0's normalized_gini_coef: 0.273728\n",
      "[900]\tvalid_0's binary_logloss: 0.151994\tvalid_0's normalized_gini_coef: 0.274352\n",
      "[1000]\tvalid_0's binary_logloss: 0.151988\tvalid_0's normalized_gini_coef: 0.274586\n",
      "[1100]\tvalid_0's binary_logloss: 0.151983\tvalid_0's normalized_gini_coef: 0.274695\n",
      "Early stopping, best iteration is:\n",
      "[1034]\tvalid_0's binary_logloss: 0.15198\tvalid_0's normalized_gini_coef: 0.274889\n",
      "CV fold 3\n",
      "Training until validation scores don't improve for 150 rounds\n",
      "[100]\tvalid_0's binary_logloss: 0.153198\tvalid_0's normalized_gini_coef: 0.284661\n",
      "[200]\tvalid_0's binary_logloss: 0.152174\tvalid_0's normalized_gini_coef: 0.291595\n",
      "[300]\tvalid_0's binary_logloss: 0.151712\tvalid_0's normalized_gini_coef: 0.297904\n",
      "[400]\tvalid_0's binary_logloss: 0.151439\tvalid_0's normalized_gini_coef: 0.302544\n",
      "[500]\tvalid_0's binary_logloss: 0.151284\tvalid_0's normalized_gini_coef: 0.305321\n",
      "[600]\tvalid_0's binary_logloss: 0.151183\tvalid_0's normalized_gini_coef: 0.30722\n",
      "[700]\tvalid_0's binary_logloss: 0.151115\tvalid_0's normalized_gini_coef: 0.308406\n",
      "[800]\tvalid_0's binary_logloss: 0.151079\tvalid_0's normalized_gini_coef: 0.309184\n",
      "[900]\tvalid_0's binary_logloss: 0.151042\tvalid_0's normalized_gini_coef: 0.309953\n",
      "[1000]\tvalid_0's binary_logloss: 0.151023\tvalid_0's normalized_gini_coef: 0.310242\n",
      "[1100]\tvalid_0's binary_logloss: 0.151015\tvalid_0's normalized_gini_coef: 0.310146\n",
      "CV fold 4\n",
      "Training until validation scores don't improve for 150 rounds\n",
      "[100]\tvalid_0's binary_logloss: 0.153469\tvalid_0's normalized_gini_coef: 0.261013\n",
      "[200]\tvalid_0's binary_logloss: 0.152631\tvalid_0's normalized_gini_coef: 0.267506\n",
      "[300]\tvalid_0's binary_logloss: 0.152265\tvalid_0's normalized_gini_coef: 0.2729\n",
      "[400]\tvalid_0's binary_logloss: 0.152057\tvalid_0's normalized_gini_coef: 0.277199\n",
      "[500]\tvalid_0's binary_logloss: 0.151943\tvalid_0's normalized_gini_coef: 0.279876\n",
      "[600]\tvalid_0's binary_logloss: 0.151866\tvalid_0's normalized_gini_coef: 0.28165\n",
      "[700]\tvalid_0's binary_logloss: 0.15182\tvalid_0's normalized_gini_coef: 0.282844\n",
      "[800]\tvalid_0's binary_logloss: 0.151798\tvalid_0's normalized_gini_coef: 0.283338\n",
      "[900]\tvalid_0's binary_logloss: 0.151786\tvalid_0's normalized_gini_coef: 0.283578\n",
      "[1000]\tvalid_0's binary_logloss: 0.151769\tvalid_0's normalized_gini_coef: 0.284028\n",
      "[1100]\tvalid_0's binary_logloss: 0.151756\tvalid_0's normalized_gini_coef: 0.284442\n",
      "[1200]\tvalid_0's binary_logloss: 0.151755\tvalid_0's normalized_gini_coef: 0.284332\n",
      "[1300]\tvalid_0's binary_logloss: 0.15175\tvalid_0's normalized_gini_coef: 0.284551\n",
      "[1400]\tvalid_0's binary_logloss: 0.151764\tvalid_0's normalized_gini_coef: 0.28403\n"
     ]
    }
   ],
   "source": [
    "preds = np.zeros(len(test))\n",
    "oof = np.zeros(len(train))\n",
    "metric_evaluations = list()\n",
    "skf = StratifiedKFold(n_splits=config.cv_folds, shuffle=True, random_state=config.random_state)\n",
    "for idx, (train_idx, valid_idx) in enumerate(skf.split(train, \n",
    "                                                       target)):\n",
    "    print(f\"CV fold {idx}\")\n",
    "    X_train, y_train = train.iloc[train_idx], target.iloc[train_idx]\n",
    "    X_valid, y_valid = train.iloc[valid_idx], target.iloc[valid_idx]\n",
    "    \n",
    "    model = lgb.LGBMClassifier(**params,\n",
    "                               n_estimators=config.n_estimators,\n",
    "                    early_stopping_round=config.early_stopping_round,\n",
    "                               force_row_wise=True)\n",
    "    \n",
    "    callbacks=[lgb.early_stopping(stopping_rounds=150), \n",
    "               lgb.log_evaluation(period=100, show_stdv=False)]\n",
    "                                                                                           \n",
    "    model.fit(X_train, y_train, \n",
    "              eval_set=[(X_valid, y_valid)], \n",
    "              eval_metric=gini_lgb, callbacks=callbacks)\n",
    "    metric_evaluations.append(\n",
    "                model.best_score_['valid_0']['normalized_gini_coef'])\n",
    "    preds += (model.predict_proba(test,  \n",
    "              num_iteration=model.best_iteration_)[:,1] \n",
    "              / skf.n_splits)\n",
    "    oof[valid_idx] = model.predict_proba(X_valid, \n",
    "                    num_iteration=model.best_iteration_)[:,1]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lightgbm cv normalized gini coeff:      0.287,      (0.014)\n"
     ]
    }
   ],
   "source": [
    "print(f\"lightgbm cv normalized gini coeff:\\\n",
    "      {np.mean(metric_evaluations):0.3f},\\\n",
    "      ({np.std(metric_evaluations):0.3f})\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission['target'] = preds\n",
    "submission.to_csv(\"lgb_submission.csv\")\n",
    "\n",
    "oofs = target.to_frame()\n",
    "oofs['target'] = oof\n",
    "oofs.to_csv('lgb_oof.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0364</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0364</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0364</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0364</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0364</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1488022</th>\n",
       "      <td>0.0364</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1488023</th>\n",
       "      <td>0.0364</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1488024</th>\n",
       "      <td>0.0364</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1488025</th>\n",
       "      <td>0.0364</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1488026</th>\n",
       "      <td>0.0364</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>892816 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         target\n",
       "id             \n",
       "0        0.0364\n",
       "1        0.0364\n",
       "2        0.0364\n",
       "3        0.0364\n",
       "4        0.0364\n",
       "...         ...\n",
       "1488022  0.0364\n",
       "1488023  0.0364\n",
       "1488024  0.0364\n",
       "1488025  0.0364\n",
       "1488026  0.0364\n",
       "\n",
       "[892816 rows x 1 columns]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
